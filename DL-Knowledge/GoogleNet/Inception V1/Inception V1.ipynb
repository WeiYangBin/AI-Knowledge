{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 224, 224, 3], name='input')\n",
    "\n",
    "\n",
    "def inception_Block(inputs, branchShape0, branchShape1_1, branchShape1_2, branchShape2_1, branchShape2_2, branchShape3):\n",
    "    \"\"\"\n",
    "    \n",
    "    定义模块化结构\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('Branch_0'):\n",
    "        branch_0 = tf.nn.conv2d(inputs, tf.Variable(tf.truncated_normal([1, 1, int(inputs.shape[3]), branchShape0])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_0 = tf.nn.bias_add(branch_0, tf.Variable(tf.constant(0.0, shape=[branchShape0])))\n",
    "        branch_0 = tf.nn.relu(branch_0)\n",
    "    with tf.variable_scope('Branch_1'):\n",
    "        branch_1 = tf.nn.conv2d(inputs, tf.Variable(tf.truncated_normal([1, 1, int(inputs.shape[3]), branchShape1_1])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_1 = tf.nn.bias_add(branch_1, tf.Variable(tf.constant(0.0, shape=[branchShape1_1])))\n",
    "        branch_1 = tf.nn.relu(branch_1)\n",
    "        branch_1 = tf.nn.conv2d(branch_1, tf.Variable(tf.truncated_normal([3, 3, branchShape1_1, branchShape1_2])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_1 = tf.nn.bias_add(branch_1, tf.Variable(tf.constant(0.0, shape=[branchShape1_2])))\n",
    "        branch_1 = tf.nn.relu(branch_1)\n",
    "    with tf.variable_scope('Branch_2'):\n",
    "        branch_2 = tf.nn.conv2d(inputs, tf.Variable(tf.truncated_normal([1, 1, int(inputs.shape[3]), branchShape2_1])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_2 = tf.nn.bias_add(branch_2, tf.Variable(tf.constant(0.0, shape=[branchShape2_1])))\n",
    "        branch_2 = tf.nn.relu(branch_2)\n",
    "        branch_2 = tf.nn.conv2d(branch_2, tf.Variable(tf.truncated_normal([5, 5, branchShape2_1, branchShape2_2])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_2 = tf.nn.bias_add(branch_2, tf.Variable(tf.constant(0.0, shape=[branchShape2_2])))\n",
    "        branch_2 = tf.nn.relu(branch_2)\n",
    "    with tf.variable_scope('Branch_3'):\n",
    "        branch_3 = tf.nn.max_pool(inputs, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        branch_3 = tf.nn.conv2d(branch_3, tf.Variable(tf.truncated_normal([1, 1, int(inputs.shape[3]), branchShape3])), strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        branch_3 = tf.nn.bias_add(branch_3, tf.Variable(tf.constant(0.0, shape=[branchShape3])))\n",
    "        branch_3 = tf.nn.relu(branch_3)\n",
    "    \n",
    "    module_block = tf.concat(axis=3, values=[branch_0, branch_1, branch_2, branch_3])\n",
    "    print('module_block :', module_block.shape)\n",
    "    \n",
    "    return module_block\n",
    "\n",
    "def inception_V1(x):\n",
    "    W_conv = {\n",
    "    'conv1': tf.Variable(tf.truncated_normal([7, 7, 3, 64])),\n",
    "    'conv2': tf.Variable(tf.truncated_normal([1, 1, 64, 192])),\n",
    "    'conv3': tf.Variable(tf.truncated_normal([3, 3, 192, 192])),\n",
    "    'fc1': tf.Variable(tf.truncated_normal([1024, 1000])),\n",
    "    'fc2': tf.Variable(tf.truncated_normal([1000, 1000])),\n",
    "    }\n",
    "\n",
    "    b_conv = {\n",
    "        'conv1': tf.Variable(tf.constant(0.0, shape=[64])),\n",
    "        'conv2': tf.Variable(tf.constant(0.0, shape=[192])),\n",
    "        'conv3': tf.Variable(tf.constant(0.0, shape=[192])),\n",
    "        'fc1': tf.Variable(tf.constant(0.1, shape=[1000])),\n",
    "        'fc2': tf.Variable(tf.constant(0.1, shape=[1000]))\n",
    "\n",
    "    }\n",
    "\n",
    "    conv1 = tf.nn.conv2d(x, W_conv['conv1'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv1 = tf.nn.bias_add(conv1, b_conv['conv1'])\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    print('conv1 :', conv1.shape)\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('pool1 :', pool1.shape)\n",
    "    norm1 = tf.nn.lrn(pool1)\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(norm1, W_conv['conv2'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, b_conv['conv2'])\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    print('conv2 :', conv2.shape)\n",
    "    \n",
    "    conv3 = tf.nn.conv2d(conv2, W_conv['conv3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv3 = tf.nn.bias_add(conv3, b_conv['conv3'])\n",
    "    print('conv3 :', conv3.shape)\n",
    "    norm2 = tf.nn.lrn(conv3)\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('pool2 :', pool2.shape)\n",
    "    \n",
    "    print('--------')   \n",
    "    print('inception_3a')\n",
    "    inception_3a = inception_Block(pool2, 64, 96, 128, 16, 32, 32)\n",
    "    print('--------')\n",
    "    print('inception_3b')\n",
    "    inception_3b = inception_Block(inception_3a, 128, 128, 192, 32, 96, 64)    \n",
    "    pool3 = tf.nn.max_pool(inception_3b, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('pool3 :', pool3.shape)\n",
    "    \n",
    "    print('--------')\n",
    "    print('inception_4a')\n",
    "    inception_4a = inception_Block(pool3, 192, 96, 208, 16, 48, 64)\n",
    "    print('--------')\n",
    "    print('inception_4b')\n",
    "    inception_4b = inception_Block(inception_4a, 160, 112, 224, 24, 64, 64)\n",
    "    print('--------')\n",
    "    print('inception_4c')\n",
    "    inception_4c = inception_Block(inception_4b, 128, 128, 256, 24, 64, 64)\n",
    "    print('--------')\n",
    "    print('inception_4d')\n",
    "    inception_4d = inception_Block(inception_4c, 112, 144, 288, 32, 64, 64)\n",
    "    print('--------')\n",
    "    print('inception_4e')\n",
    "    inception_4e = inception_Block(inception_4d, 256, 160, 320, 32, 128, 128)\n",
    "    pool4 = tf.nn.max_pool(inception_4e, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    print('pool4 :', pool4.shape)\n",
    "    \n",
    "    print('--------')\n",
    "    print('inception_5a')\n",
    "    inception_5a = inception_Block(pool4, 256, 160, 320, 32, 128, 128)\n",
    "    print('--------')\n",
    "    print('inception_5b')\n",
    "    inception_5b = inception_Block(inception_5a, 384, 192, 384, 48, 128, 128)\n",
    "    pool5 = tf.nn.avg_pool(inception_5b, ksize=[1, 7, 7, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    print('pool5 :', pool5.shape)\n",
    "    pool5 = tf.nn.dropout(pool5, 0.4)\n",
    "    \n",
    "    \n",
    "    print('--------')\n",
    "    reshape = tf.reshape(pool5, [-1, 1 * 1 * 1024])\n",
    "    fc1 = tf.add(tf.matmul(reshape, W_conv['fc1']), b_conv['fc1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print('fc1 :', fc1.shape)\n",
    "\n",
    "    output = tf.nn.softmax(tf.add(tf.matmul(fc1, W_conv['fc2']), b_conv['fc2']))\n",
    "    print('output :', output.shape)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 : (?, 112, 112, 64)\n",
      "pool1 : (?, 56, 56, 64)\n",
      "conv2 : (?, 56, 56, 192)\n",
      "conv3 : (?, 56, 56, 192)\n",
      "pool2 : (?, 28, 28, 192)\n",
      "--------\n",
      "inception_3a\n",
      "module_block : (?, 28, 28, 256)\n",
      "--------\n",
      "inception_3b\n",
      "module_block : (?, 28, 28, 480)\n",
      "pool3 : (?, 14, 14, 480)\n",
      "--------\n",
      "inception_4a\n",
      "module_block : (?, 14, 14, 512)\n",
      "--------\n",
      "inception_4b\n",
      "module_block : (?, 14, 14, 512)\n",
      "--------\n",
      "inception_4c\n",
      "module_block : (?, 14, 14, 512)\n",
      "--------\n",
      "inception_4d\n",
      "module_block : (?, 14, 14, 528)\n",
      "--------\n",
      "inception_4e\n",
      "module_block : (?, 14, 14, 832)\n",
      "pool4 : (?, 7, 7, 832)\n",
      "--------\n",
      "inception_5a\n",
      "module_block : (?, 7, 7, 832)\n",
      "--------\n",
      "inception_5b\n",
      "module_block : (?, 7, 7, 1024)\n",
      "pool5 : (?, 1, 1, 1024)\n",
      "--------\n",
      "fc1 : (?, 1000)\n",
      "output : (?, 1000)\n"
     ]
    }
   ],
   "source": [
    "inception_V1 = inception_V1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
